{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f4badf",
   "metadata": {},
   "source": [
    "\n",
    "# IE6483 Project 1 — Sentiment Classification (End-to-End, English)\n",
    "\n",
    "This notebook is ready to run on a single NVIDIA GPU (e.g., RTX A6000) or Apple Silicon (MPS).\n",
    "It covers: environment sanity checks, data loading, a TF-IDF+LogReg baseline, and a BERT fine-tuning pipeline.\n",
    "It also generates `submission.csv` for the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea57cdd",
   "metadata": {},
   "source": [
    "\n",
    "## Environment notes (read once)\n",
    "\n",
    "- Use Python 3.10/3.11. Install PyTorch matching your CUDA version (A6000 → CUDA 11.8/12.x).  \n",
    "- Transformers >= **4.46** uses `eval_strategy` instead of `evaluation_strategy` in `TrainingArguments`; this notebook adapts automatically.  \n",
    "- For throughput on Ampere GPUs (A6000), enabling **TF32** (and BF16 if supported) can speed up training. See: `torch.set_float32_matmul_precision('high')` docs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48e9d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19 (main, Oct 21 2025, 16:43:05) [GCC 11.2.0]\n",
      "PyTorch: 2.7.1+cu118 | CUDA available: True\n",
      "GPU: NVIDIA RTX A6000\n",
      "MPS available: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, platform, sys, json, random, math, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import torch\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a6b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 matmul precision: high\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch, random, numpy as np\n",
    "from transformers import set_seed\n",
    "set_seed(42)\n",
    "random.seed(42); np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "# Enable TF32 path for matmul on Ampere+ (improves perf with tiny precision tradeoff)\n",
    "torch.set_float32_matmul_precision(\"high\")  # https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html\n",
    "print(\"float32 matmul precision:\", torch.get_float32_matmul_precision())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca61963",
   "metadata": {},
   "source": [
    "\n",
    "## Load data\n",
    "\n",
    "Expected schema:\n",
    "- `train.json`: list of dicts with `reviews` (text) and `sentiments` (0/1)\n",
    "- `test.json`: list of dicts with `reviews`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffed54f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path: ../train.json\n",
      "test_path : ../test.json\n",
      "                                             reviews  sentiments\n",
      "0  I bought this belt for my daughter in-law for ...           1\n",
      "1  The size was perfect and so was the color.  It...           1\n",
      "sentiments\n",
      "1    6319\n",
      "0    1082\n",
      "Name: count, dtype: int64\n",
      "train size: 7401 | test size: 1851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "cwd = Path(\".\").resolve()\n",
    "train_path = \"../train.json\"\n",
    "test_path  = \"../test.json\"\n",
    "print(\"train_path:\", train_path)\n",
    "print(\"test_path :\", test_path)\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(test_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df  = pd.DataFrame(test_data)\n",
    "\n",
    "assert {\"reviews\",\"sentiments\"}.issubset(train_df.columns), \"train.json must have reviews & sentiments\"\n",
    "assert \"reviews\" in test_df.columns, \"test.json must have reviews\"\n",
    "\n",
    "print(train_df.head(2))\n",
    "print(train_df['sentiments'].value_counts(dropna=False))\n",
    "print(\"train size:\", len(train_df), \"| test size:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebd6dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_split: (5920, 3) | valid_split: (1481, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def clean_text(x):\n",
    "    if not isinstance(x, str): return \"\"\n",
    "    return x.strip()\n",
    "\n",
    "train_df[\"text\"] = train_df[\"reviews\"].apply(clean_text)\n",
    "test_df[\"text\"]  = test_df[\"reviews\"].apply(clean_text)\n",
    "\n",
    "train_split, valid_split = train_test_split(\n",
    "    train_df, test_size=0.2, random_state=42, stratify=train_df[\"sentiments\"]\n",
    ")\n",
    "print(\"train_split:\", train_split.shape, \"| valid_split:\", valid_split.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9345a9",
   "metadata": {},
   "source": [
    "\n",
    "## Baseline 1 — TF-IDF + Logistic Regression\n",
    "\n",
    "A strong classical baseline: n-gram TF-IDF + L2-logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ddaa0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TFIDF+LR] Valid Acc=0.8893 | F1=0.9391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.2442    0.3926       217\n",
      "           1     0.8852    1.0000    0.9391      1264\n",
      "\n",
      "    accuracy                         0.8893      1481\n",
      "   macro avg     0.9426    0.6221    0.6658      1481\n",
      "weighted avg     0.9020    0.8893    0.8590      1481\n",
      "\n",
      "Saved: outputs/submission_tfidf.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import joblib, os\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "tfidf_clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), max_features=50000, min_df=2)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, solver=\"saga\", random_state=55)),\n",
    "])\n",
    "\n",
    "tfidf_clf.fit(train_split[\"text\"], train_split[\"sentiments\"])\n",
    "valid_pred = tfidf_clf.predict(valid_split[\"text\"])\n",
    "acc = accuracy_score(valid_split[\"sentiments\"], valid_pred)\n",
    "f1  = f1_score(valid_split[\"sentiments\"], valid_pred)\n",
    "print(f\"[TFIDF+LR] Valid Acc={acc:.4f} | F1={f1:.4f}\")\n",
    "print(classification_report(valid_split[\"sentiments\"], valid_pred, digits=4))\n",
    "\n",
    "joblib.dump(tfidf_clf, \"outputs/tfidf_logreg.joblib\")\n",
    "pd.DataFrame({\"sentiments\": tfidf_clf.predict(test_df[\"text\"])}).to_csv(\"outputs/submission_tfidf.csv\", index=False)\n",
    "print(\"Saved:\", \"outputs/submission_tfidf.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee6483",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
