{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b3d9c2",
   "metadata": {},
   "source": [
    "# IE6483 Project 1 — RNN (BiLSTM) Sentiment Classifier\n",
    "\n",
    "**Notebook generated on:** 2025-11-04 05:35:16\n",
    "\n",
    "本 notebook 依照课程项目要求构建了一个可复现的 **BiLSTM（RNN）情感分类** 管线：\n",
    "- 数据读取：`train.json` / `test.json`（字段：`reviews`，`sentiments`）。\n",
    "- 词表与分词：`torchtext` 的 `basic_english`；如不可用，退化到正则分词。\n",
    "- 模型：变长序列 + `pack_padded_sequence` 的 BiLSTM，二分类头。\n",
    "- 训练：AdamW，梯度裁剪，`ReduceLROnPlateau` 学习率调度，早停与最优模型保存。\n",
    "- 日志：Python `logging` 同步写入控制台与 `train.log`，并显示 tqdm 进度条。\n",
    "- 结果：对测试集输出 `submission.csv`（一列：`sentiments`，0/1）。\n",
    "\n",
    "> 运行前，请将 `train.json` 与 `test.json` 放在当前工作目录。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f738e",
   "metadata": {},
   "source": [
    "## 0. 环境与设备\n",
    "\n",
    "- 推荐 OS：Ubuntu 22.04（或等价 Linux）  \n",
    "- Python：3.10+  \n",
    "- PyTorch：2.x（建议 2.7+），CUDA 12.x（如 12.6/12.8）  \n",
    "- GPU：NVIDIA RTX A6000（Ampere GA102，单卡即可；CPU 下也可运行）  \n",
    "- CPU：Xeon Silver 系列兼容（无需特殊指令集）\n",
    "\n",
    "> 下方 cell 会自动检测 `torch.cuda`、打印设备与关键库版本。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 可选：仅当你的环境未安装相应依赖时再执行本单元\n",
    "# 在本评测环境中禁用了联网安装，这里只是提供命令参考：\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torch torchtext pandas scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83822971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python : 3.10.19 (main, Oct 21 2025, 16:43:05) [GCC 11.2.0]\n",
      "Platform: Linux-5.15.0-1027-oracle-x86_64-with-glibc2.31\n",
      "PyTorch : 2.7.1+cu118\n",
      "Pandas  : 2.3.3\n",
      "sklearn : 1.7.2\n",
      "CUDA    : available\n",
      "GPU     : NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import platform, torch, sys\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import importlib\n",
    "\n",
    "print(\"Python :\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"PyTorch :\", torch.__version__)\n",
    "print(\"Pandas  :\", pd.__version__)\n",
    "print(\"sklearn :\", sklearn.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA    : available\")\n",
    "    print(\"GPU     :\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA    : not available (running on CPU)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09df0a",
   "metadata": {},
   "source": [
    "## 1. 日志初始化（打印到控制台 + 写入 train.log）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3354739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:25] [INFO] Logger initialized. Writing to train.log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import logging, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_logger(log_file: str = \"train.log\", level=logging.INFO):\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = []  # reset existing handlers in notebooks\n",
    "    logger.setLevel(level)\n",
    "    fmt = logging.Formatter(\"[%(asctime)s] [%(levelname)s] %(message)s\", \"%H:%M:%S\")\n",
    "\n",
    "    # console\n",
    "    ch = logging.StreamHandler(stream=sys.stdout)\n",
    "    ch.setLevel(level)\n",
    "    ch.setFormatter(fmt)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    # file\n",
    "    fh = logging.FileHandler(log_file, mode=\"w\", encoding=\"utf-8\")\n",
    "    fh.setLevel(level)\n",
    "    fh.setFormatter(fmt)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    logger.info(\"Logger initialized. Writing to %s\", log_file)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b84b4",
   "metadata": {},
   "source": [
    "## 2. 随机性与确定性设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493f76d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:28] [INFO] Deterministic mode enabled with seed=42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, random, torch, numpy as np\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ.setdefault(\"CUBLAS_WORKSPACE_CONFIG\", \":16:8\")\n",
    "    logger.info(\"Deterministic mode enabled with seed=%d\", seed)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f27b6a",
   "metadata": {},
   "source": [
    "## 3. 数据读取与预处理\n",
    "\n",
    "- 期望字段：`reviews`（文本），`sentiments`（0/1，仅训练集）。\n",
    "- 自动兼容 JSON/JSONL/CSV 常见方言。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fecf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this belt for my daughter in-law for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The size was perfect and so was the color.  It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fits and feels good, esp. for doing a swim rac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiments\n",
       "0  I bought this belt for my daughter in-law for ...           1\n",
       "1  The size was perfect and so was the color.  It...           1\n",
       "2  Fits and feels good, esp. for doing a swim rac...           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def read_json_flexible(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    # Try JSON Lines\n",
    "    try:\n",
    "        df = pd.read_json(p, lines=True)\n",
    "        if \"reviews\" in df.columns:\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try regular JSON\n",
    "    try:\n",
    "        df = pd.read_json(p)\n",
    "        if \"reviews\" in df.columns:\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Try CSV fallback\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        if \"reviews\" in df.columns:\n",
    "            return df\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    raise ValueError(f\"Unsupported data format in {path}. Expected a 'reviews' column.\")\n",
    "\n",
    "# 路径可按需修改\n",
    "TRAIN_PATH = \"../train.json\"\n",
    "TEST_PATH  = \"../test.json\"\n",
    "\n",
    "train_df = read_json_flexible(TRAIN_PATH)\n",
    "test_df  = read_json_flexible(TEST_PATH)\n",
    "\n",
    "assert \"reviews\" in train_df.columns and \"reviews\" in test_df.columns, \"缺少 'reviews' 列\"\n",
    "assert \"sentiments\" in train_df.columns, \"训练集缺少 'sentiments' 列\"\n",
    "\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088c4ad",
   "metadata": {},
   "source": [
    "## 4. 分词与词表（`torchtext` 的 `basic_english`，失败则退化到正则分词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23db0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:37] [WARNING] torchtext unavailable; fall back to regex tokenizer.\n",
      "[14:55:37] [INFO] Vocab size: 7797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "def get_basic_tokenizer():\n",
    "    try:\n",
    "        from torchtext.data.utils import get_tokenizer\n",
    "        tok = get_tokenizer(\"basic_english\")\n",
    "        logger.info(\"Using torchtext basic_english tokenizer.\")\n",
    "        return tok\n",
    "    except Exception:\n",
    "        pattern = re.compile(r\"[A-Za-z0-9']+\")\n",
    "        logger.warning(\"torchtext unavailable; fall back to regex tokenizer.\")\n",
    "        return lambda s: pattern.findall(s.lower())\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, counter: Dict[str, int], min_freq: int = 2, specials: Optional[List[str]] = None, max_size: Optional[int] = 50000):\n",
    "        self.pad_token = \"<pad>\"\n",
    "        self.unk_token = \"<unk>\"\n",
    "        specials = specials or [self.pad_token, self.unk_token]\n",
    "\n",
    "        items = [(w, c) for w, c in counter.items() if c >= min_freq]\n",
    "        items.sort(key=lambda x: (-x[1], x[0]))\n",
    "        if max_size is not None:\n",
    "            items = items[:max_size - len(specials)]\n",
    "        itos = specials + [w for w, _ in items]\n",
    "        self.itos = itos\n",
    "        self.stoi = {w: i for i, w in enumerate(itos)}\n",
    "        self.pad_idx = self.stoi[self.pad_token]\n",
    "        self.unk_idx = self.stoi[self.unk_token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def encode(self, tokens: List[str]) -> List[int]:\n",
    "        return [self.stoi.get(t, self.unk_idx) for t in tokens]\n",
    "\n",
    "def build_vocab(texts: List[str], tokenizer, min_freq=2, max_size=50000) -> Vocab:\n",
    "    counter = {}\n",
    "    for t in texts:\n",
    "        for tok in tokenizer(str(t)):\n",
    "            counter[tok] = counter.get(tok, 0) + 1\n",
    "    return Vocab(counter, min_freq=min_freq, max_size=max_size)\n",
    "\n",
    "def encode_text(text: str, tokenizer, vocab: Vocab, max_len: int = 256):\n",
    "    tokens = tokenizer(str(text))\n",
    "    ids = vocab.encode(tokens[:max_len])\n",
    "    return ids\n",
    "\n",
    "tokenizer = get_basic_tokenizer()\n",
    "vocab = build_vocab(train_df[\"reviews\"].astype(str).tolist(), tokenizer, min_freq=2, max_size=50000)\n",
    "logger.info(\"Vocab size: %d\", len(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277e518",
   "metadata": {},
   "source": [
    "## 5. Dataset 与 DataLoader（包含变长 padding 与 `collate_fn`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2018919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:56:21] [INFO] Train/Val sizes: 5920 / 1481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, vocab, max_len=256):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = None if labels is None else list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ids = encode_text(self.texts[idx], self.tokenizer, self.vocab, self.max_len)\n",
    "        y = None if self.labels is None else int(self.labels[idx])\n",
    "        return ids, y\n",
    "\n",
    "def collate_batch(batch, pad_idx: int):\n",
    "    lengths = [len(x[0]) for x in batch]\n",
    "    max_len = max(lengths) if lengths else 0\n",
    "    padded, labels = [], []\n",
    "    for ids, y in batch:\n",
    "        padded.append(ids + [pad_idx] * (max_len - len(ids)))\n",
    "        if y is not None:\n",
    "            labels.append(y)\n",
    "    x = torch.tensor(padded, dtype=torch.long)\n",
    "    lens = torch.tensor(lengths, dtype=torch.long)\n",
    "    y = None if len(labels) == 0 else torch.tensor(labels, dtype=torch.float32)\n",
    "    return x, lens, y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "tr_texts, va_texts, tr_labels, va_labels = train_test_split(\n",
    "    train_df[\"reviews\"].astype(str).tolist(),\n",
    "    train_df[\"sentiments\"].astype(int).tolist(),\n",
    "    test_size=0.2, random_state=42, stratify=train_df[\"sentiments\"].astype(int).tolist()\n",
    ")\n",
    "\n",
    "max_len = 256\n",
    "tr_ds = TextDataset(tr_texts, tr_labels, tokenizer, vocab, max_len=max_len)\n",
    "va_ds = TextDataset(va_texts, va_labels, tokenizer, vocab, max_len=max_len)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "collate = lambda b: collate_batch(b, vocab.pad_idx)\n",
    "num_workers = 2 if os.name != \"nt\" else 0\n",
    "pin_memory = True if torch.cuda.is_available() else False\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, batch_size=64, shuffle=True, collate_fn=collate, num_workers=num_workers, pin_memory=pin_memory)\n",
    "va_loader = DataLoader(va_ds, batch_size=64, shuffle=False, collate_fn=collate, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "logger.info(\"Train/Val sizes: %d / %d\", len(tr_ds), len(va_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5c365",
   "metadata": {},
   "source": [
    "## 6. BiLSTM 模型（变长序列 + `pack_padded_sequence`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92998d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:58] [INFO] Model built: BiLSTMClassifier (params: 4074857)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int = 200, hidden_dim: int = 256,\n",
    "                 num_layers: int = 2, dropout: float = 0.3, pad_idx: int = 0, bidirectional: bool = True):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.bidirectional = bidirectional\n",
    "        out_dim = hidden_dim * (2 if bidirectional else 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(out_dim, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.embedding(x)                       # [B, T, E]\n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)               # h_n: [L*D, B, H]\n",
    "        if self.bidirectional:\n",
    "            h_fwd, h_bwd = h_n[-2], h_n[-1]\n",
    "            h = torch.cat([h_fwd, h_bwd], dim=1)      # [B, 2H]\n",
    "        else:\n",
    "            h = h_n[-1]                               # [B, H]\n",
    "        h = self.dropout(h)\n",
    "        return self.fc(h).squeeze(1)                  # [B]\n",
    "\n",
    "model = BiLSTMClassifier(vocab_size=len(vocab), embed_dim=200, hidden_dim=256, num_layers=2, dropout=0.3, pad_idx=vocab.pad_idx).to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "logger.info(\"Model built: %s (params: %d)\", model.__class__.__name__, total_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c13d4",
   "metadata": {},
   "source": [
    "## 7. 训练与验证（带日志、早停、学习率调度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b3847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e850a13677b14439aa9b54abc83de2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/8:   0%|          | 0/93 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, lengths, y in loader:\n",
    "            x, lengths, y = x.to(device), lengths.to(device), y.to(device)\n",
    "            logits = model(x, lengths)\n",
    "            loss = criterion(logits, y)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).long()\n",
    "            total += x.size(0)\n",
    "            correct += (preds == y.long()).sum().item()\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "    return loss_sum / total, correct / total\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_path = \"checkpoints/bilstm_best.pt\"\n",
    "os.makedirs(os.path.dirname(best_path), exist_ok=True)\n",
    "epochs = 8\n",
    "patience, bad_epochs = 3, 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(tr_loader, desc=f\"Epoch {epoch}/{epochs}\")\n",
    "    for x, lengths, y in pbar:\n",
    "        x, lengths, y = x.to(device), lengths.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x, lengths)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, va_loader, device)\n",
    "    scheduler.step(val_loss)\n",
    "    logger.info(\"[Val] loss=%.4f acc=%.4f lr=%.6f\", val_loss, val_acc, optimizer.param_groups[0][\"lr\"])\n",
    "\n",
    "    if val_loss < best_val - 1e-6:\n",
    "        best_val = val_loss\n",
    "        torch.save({\"state_dict\": model.state_dict(), \"cfg\": {\n",
    "            \"vocab_itos\": vocab.itos,\n",
    "            \"pad_idx\": vocab.pad_idx,\n",
    "            \"embed_dim\": 200, \"hidden_dim\": 256, \"num_layers\": 2, \"dropout\": 0.3, \"max_len\": 256\n",
    "        }}, best_path)\n",
    "        logger.info(\"Saved best checkpoint -> %s\", best_path)\n",
    "        bad_epochs = 0\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        if bad_epochs >= patience:\n",
    "            logger.info(\"Early stopping at epoch=%d (no improvement for %d epochs).\", epoch, patience)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182b392",
   "metadata": {},
   "source": [
    "## 8. 加载最优权重并在测试集生成提交文件 `submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b568806",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 重新加载最优权重（以及词表）\n",
    "ckpt = torch.load(\"checkpoints/bilstm_best.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "# 词表（如果你在独立推理脚本中运行，需要反序列化 itos；这里直接沿用 notebook 内的 vocab 实例即可）\n",
    "\n",
    "test_ds = TextDataset(test_df['reviews'].astype(str).tolist(), labels=None, tokenizer=tokenizer, vocab=vocab, max_len=256)\n",
    "test_loader = DataLoader(test_ds, batch_size=128, shuffle=False, collate_fn=lambda b: collate_batch(b, vocab.pad_idx),\n",
    "                         num_workers=2 if os.name!=\"nt\" else 0, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for x, lengths, _ in tqdm(test_loader, desc=\"Predict\"):\n",
    "        x, lengths = x.to(device), lengths.to(device)\n",
    "        logits = model(x, lengths)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds.extend((probs >= 0.5).long().cpu().tolist())\n",
    "\n",
    "sub = pd.DataFrame({\"sentiments\": preds})\n",
    "out_csv = \"submission.csv\"\n",
    "sub.to_csv(out_csv, index=False)\n",
    "logger.info(\"Wrote predictions -> %s (head):\\n%s\", out_csv, sub.head(5))\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02de5ae",
   "metadata": {},
   "source": [
    "## 9. 备注与对齐\n",
    "\n",
    "- 该 RNN 实现严格采用 `pack_padded_sequence` 处理变长序列，避免无效填充的计算；\n",
    "- 采用 `torch.use_deterministic_algorithms(True)` 与固定随机种子，便于复现实验；\n",
    "- 训练日志既打印到控制台也写入 `train.log`，并保存最优检查点到 `checkpoints/`；\n",
    "- 满足项目要求：输入/输出字段、二分类、导出 `submission.csv`。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee6483",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
